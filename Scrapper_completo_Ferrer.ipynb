{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+HJmyRa+NM2vK9mtsROo2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanfernandev/Teamwork-Extended-Functions/blob/main/Scrapper_completo_Ferrer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qso-EKacPysI",
        "outputId": "a6b20f1c-4294-4114-accd-4491d3366af5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Extrayendo categor√≠as...\n",
            "üî¨ Modo TEST activado. Procesando solo: https://www.farmaferrer.com/higiene/higiene-corporal/desodorantes\n",
            "\n",
            "üî¨ MODO TEST: Procesando 2 p√°ginas de Higiene > Desodorantes\n",
            "  üìë P√°ginas a procesar: 2/2\n",
            "  üìÑ P√°gina 1: 10 productos encontrados\n",
            "    üõí (1/10) Extrayendo: be-desodorante-antitranspirante-72-h--50-ml\n",
            "    üõí (2/10) Extrayendo: desodorante-vichy-homme-48h\n",
            "‚ö†Ô∏è Error leyendo JSON-LD en https://www.farmaferrer.com/desodorante-vichy-homme-48h: Invalid control character at: line 8 column 48 (char 424)\n",
            "    üõí (3/10) Extrayendo: martiderm-desodorante-48h-driosec-dermoprotect-roll-on-50-ml\n",
            "    üõí (4/10) Extrayendo: medicis-desod-roll-on\n",
            "    üõí (5/10) Extrayendo: lambda-control-desod-cr\n",
            "    üõí (6/10) Extrayendo: martiderm-drios-desod-roll-on\n",
            "    üõí (7/10) Extrayendo: isdindeo-lambda-control-48-h-50ml\n",
            "‚ö†Ô∏è Error leyendo JSON-LD en https://www.farmaferrer.com/isdindeo-lambda-control-48-h-50ml: Invalid control character at: line 8 column 48 (char 317)\n",
            "    üõí (8/10) Extrayendo: lambda-cont-des-roll-on-emu\n",
            "    üõí (9/10) Extrayendo: la-roche-posay-desodorante-fisiologico-24-h--roll-on-50-ml\n",
            "    üõí (10/10) Extrayendo: farmafeet-spray-antitranspirante-desodorante-y-refrescante-150-ml\n",
            "‚ö†Ô∏è Error leyendo JSON-LD en https://www.farmaferrer.com/farmafeet-spray-antitranspirante-desodorante-y-refrescante-150-ml: Invalid control character at: line 8 column 48 (char 395)\n",
            "  üìÑ P√°gina 2: 8 productos encontrados\n",
            "    üõí (1/8) Extrayendo: atencion-farmaceutica\n",
            "    üõí (2/8) Extrayendo: mussvital-essentials-botanics-antitranspirante-forte--2-x-75-ml\n",
            "‚ö†Ô∏è Error leyendo JSON-LD en https://www.farmaferrer.com/mussvital-essentials-botanics-antitranspirante-forte--2-x-75-ml: Invalid control character at: line 6 column 92 (char 248)\n",
            "    üõí (3/8) Extrayendo: vichy-desod-regulador-roll-on\n",
            "    üõí (4/8) Extrayendo: vichy-desod-regulador-spray\n",
            "    üõí (5/8) Extrayendo: tratamiento-antitraspirante-48-horas--roll-on-50-ml\n",
            "    üõí (6/8) Extrayendo: roger--gallet-cofre-navidad-homme-menthe\n",
            "‚ö†Ô∏è Error leyendo JSON-LD en https://www.farmaferrer.com/roger--gallet-cofre-navidad-homme-menthe: Invalid control character at: line 8 column 48 (char 340)\n",
            "    üõí (7/8) Extrayendo: vichy-desod-bola-sin-sal-alum\n",
            "    üõí (8/8) Extrayendo: vichy-desod-piel-sens-roll-on\n",
            "\n",
            "‚úÖ Proceso completado. Datos guardados en productos_test.csv\n",
            "üìä Total de productos extra√≠dos: 18\n"
          ]
        }
      ],
      "source": [
        "# Configurar opciones de Chrome\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Ejecutar en modo sin cabeza\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Inicializar el navegador\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import re\n",
        "import csv\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Configuraci√≥n com√∫n\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "FIELDS = [\n",
        "    \"url\", \"productID\", \"name\", \"description\", \"image\", \"brand\",\n",
        "    \"price\", \"priceCurrency\", \"availability\",\n",
        "    \"short_description\", \"product_reference\",\n",
        "    \"long_description\", \"pharma_advice\",\n",
        "    \"original_price\", \"current_price\",\n",
        "    \"category\", \"category_parent\"\n",
        "]\n",
        "\n",
        "# Configurar navegador headless\n",
        "def setup_driver():\n",
        "    options = Options()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    options.add_argument('--disable-gpu')\n",
        "    options.add_argument('--window-size=1920x1080')\n",
        "    return webdriver.Chrome(options=options)\n",
        "\n",
        "# Funci√≥n para extraer URLs de onclick\n",
        "def extraer_url_onclick(onclick_val):\n",
        "    match = re.search(r\"setLocation\\('([^']+)'\\)\", onclick_val or '')\n",
        "    if match:\n",
        "        return 'https://www.farmaferrer.com' + match.group(1)\n",
        "    return ''\n",
        "\n",
        "# Extraer todas las categor√≠as\n",
        "def extraer_categorias():\n",
        "    driver = setup_driver()\n",
        "    driver.get('https://www.farmaferrer.com/')\n",
        "    wait = WebDriverWait(driver, 10)\n",
        "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'ul.mega > li.nivel-0')))\n",
        "\n",
        "    categorias_extraidas = []\n",
        "    categorias = driver.find_elements(By.CSS_SELECTOR, 'ul.mega > li.nivel-0')\n",
        "\n",
        "    for categoria in categorias:\n",
        "        try:\n",
        "            nombre_padre = categoria.find_element(By.TAG_NAME, 'a').get_attribute('textContent').strip()\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            seccion = categoria.find_element(By.CSS_SELECTOR, 'section')\n",
        "            bloques_l2 = seccion.find_elements(By.CSS_SELECTOR, 'ul.menu-l-2 > li')\n",
        "\n",
        "            for bloque in bloques_l2:\n",
        "                try:\n",
        "                    subcat_l2_a = bloque.find_element(By.TAG_NAME, 'a')\n",
        "                    subcat_l2_nombre = subcat_l2_a.get_attribute('textContent').strip()\n",
        "                    href = subcat_l2_a.get_attribute('href')\n",
        "                    onclick = subcat_l2_a.get_attribute('onclick')\n",
        "                    subcat_l2_url = href if href else extraer_url_onclick(onclick)\n",
        "\n",
        "                    categorias_extraidas.append({\n",
        "                        'categoria_padre': nombre_padre,\n",
        "                        'categoria': subcat_l2_nombre,\n",
        "                        'url': subcat_l2_url\n",
        "                    })\n",
        "\n",
        "                    subsubs = bloque.find_elements(By.CSS_SELECTOR, 'ul.menu-l-3 > li > a')\n",
        "                    for subsub in subsubs:\n",
        "                        nombre_l3 = subsub.get_attribute('textContent').strip()\n",
        "                        href_l3 = subsub.get_attribute('href')\n",
        "                        onclick_l3 = subsub.get_attribute('onclick')\n",
        "                        url_l3 = href_l3 if href_l3 else extraer_url_onclick(onclick_l3)\n",
        "\n",
        "                        categorias_extraidas.append({\n",
        "                            'categoria_padre': nombre_padre,\n",
        "                            'categoria': nombre_l3,\n",
        "                            'url': url_l3\n",
        "                        })\n",
        "                except:\n",
        "                    continue\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    driver.quit()\n",
        "    return categorias_extraidas\n",
        "\n",
        "# Obtener todas las p√°ginas de una categor√≠a\n",
        "def get_all_pages_in_category(category_url):\n",
        "    res = requests.get(category_url, headers=HEADERS)\n",
        "    res.raise_for_status()\n",
        "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "    pages = [category_url]\n",
        "    paginacion = soup.select(\"div.paginacion-listado ul.pagination li a[href]\")\n",
        "\n",
        "    for link in paginacion:\n",
        "        href = link.get(\"href\")\n",
        "        if href and href not in pages:\n",
        "            # Normalizar URLs para evitar duplicados\n",
        "            normalized = href.split('?')[0]  # Eliminar par√°metros de consulta\n",
        "            if normalized not in [p.split('?')[0] for p in pages]:\n",
        "                pages.append(href)\n",
        "\n",
        "    # Eliminar posibles duplicados manteniendo el orden\n",
        "    seen = set()\n",
        "    unique_pages = []\n",
        "    for page in pages:\n",
        "        key = page.split('?')[0]\n",
        "        if key not in seen:\n",
        "            seen.add(key)\n",
        "            unique_pages.append(page)\n",
        "\n",
        "    return unique_pages\n",
        "\n",
        "# Obtener links de productos desde una p√°gina de categor√≠a\n",
        "def get_product_links_from_page(page_url):\n",
        "    res = requests.get(page_url, headers=HEADERS)\n",
        "    res.raise_for_status()\n",
        "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "    productos = soup.select(\"div.element-producto a[href]\")\n",
        "    links = []\n",
        "    for a in productos:\n",
        "        href = a.get(\"href\")\n",
        "        if href and href.startswith(\"http\"):\n",
        "            links.append(href)\n",
        "    return list(set(links))\n",
        "\n",
        "# Extraer detalles de un producto\n",
        "def extract_product_details(url, categoria_padre, categoria):\n",
        "    res = requests.get(url, headers=HEADERS)\n",
        "    res.raise_for_status()\n",
        "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "    data = dict.fromkeys(FIELDS, \"\")\n",
        "    data[\"url\"] = url\n",
        "    data[\"category_parent\"] = categoria_padre\n",
        "    data[\"category\"] = categoria\n",
        "\n",
        "    # JSON-LD\n",
        "    for script in soup.find_all(\"script\", type=\"application/ld+json\"):\n",
        "        try:\n",
        "            json_data = json.loads(script.string.strip())\n",
        "            if isinstance(json_data, list):\n",
        "                for obj in json_data:\n",
        "                    if obj.get(\"@type\") == \"Product\":\n",
        "                        json_data = obj\n",
        "                        break\n",
        "            elif json_data.get(\"@type\") != \"Product\":\n",
        "                continue\n",
        "\n",
        "            data[\"productID\"] = json_data.get(\"productID\", \"\")\n",
        "            data[\"name\"] = json_data.get(\"name\", \"\")\n",
        "            data[\"description\"] = json_data.get(\"description\", \"\")\n",
        "\n",
        "            image = json_data.get(\"image\", \"\")\n",
        "            if isinstance(image, list):\n",
        "                data[\"image\"] = image[0]\n",
        "            elif isinstance(image, str):\n",
        "                data[\"image\"] = image.strip()\n",
        "\n",
        "            brand = json_data.get(\"brand\", \"\")\n",
        "            if isinstance(brand, dict):\n",
        "                data[\"brand\"] = brand.get(\"name\", \"\")\n",
        "            elif isinstance(brand, str):\n",
        "                data[\"brand\"] = brand\n",
        "\n",
        "            offers = json_data.get(\"offers\", [])\n",
        "            if isinstance(offers, dict):\n",
        "                offers = [offers]\n",
        "            if offers:\n",
        "                offer = offers[0]\n",
        "                data[\"price\"] = offer.get(\"price\", \"\")\n",
        "                data[\"priceCurrency\"] = offer.get(\"priceCurrency\", \"\")\n",
        "                data[\"availability\"] = offer.get(\"availability\", \"\")\n",
        "\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error leyendo JSON-LD en {url}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Descripci√≥n corta + referencia\n",
        "    info_divs = soup.select(\"div.informacion\")\n",
        "    if len(info_divs) >= 2:\n",
        "        info_div = info_divs[1]\n",
        "    else:\n",
        "        info_div = info_divs[0] if info_divs else None\n",
        "\n",
        "    if info_div:\n",
        "        short = info_div.select_one(\"h4 span\")\n",
        "        if short:\n",
        "            data[\"short_description\"] = short.text.strip()\n",
        "        ref = info_div.select_one(\"span.referencia-producto strong\")\n",
        "        if ref:\n",
        "            data[\"product_reference\"] = ref.text.strip()\n",
        "\n",
        "    # Descripci√≥n larga\n",
        "    long_desc = soup.select_one(\"div#info\")\n",
        "    if long_desc:\n",
        "        data[\"long_description\"] = long_desc.get_text(separator=\"\\n\", strip=True)\n",
        "\n",
        "    # Consejo farmac√©utico\n",
        "    consejo = soup.select_one(\"div#consejo\")\n",
        "    if consejo:\n",
        "        data[\"pharma_advice\"] = consejo.get_text(separator=\"\\n\", strip=True)\n",
        "\n",
        "    # Precios\n",
        "    original_price = soup.select_one(\"h3 span.precio-original\")\n",
        "    if original_price:\n",
        "        data[\"original_price\"] = original_price.text.strip()\n",
        "\n",
        "    current_price = soup.select_one(\"h3.precio span\")\n",
        "    if current_price:\n",
        "        data[\"current_price\"] = current_price.text.strip()\n",
        "\n",
        "    return data\n",
        "\n",
        "# Guardar en CSV\n",
        "def save_to_csv(productos, filename=\"productos_farmaferrer.csv\"):\n",
        "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=FIELDS)\n",
        "        writer.writeheader()\n",
        "        for producto in productos:\n",
        "            writer.writerow(producto)\n",
        "\n",
        "# Funci√≥n principal\n",
        "def main(test_mode=False, test_category=None):\n",
        "    # Extraer todas las categor√≠as\n",
        "    print(\"üîç Extrayendo categor√≠as...\")\n",
        "    categorias = extraer_categorias()\n",
        "\n",
        "    if test_mode and test_category:\n",
        "        # Modo test: usar solo la categor√≠a de prueba\n",
        "        categorias = [cat for cat in categorias if test_category in cat['url']]\n",
        "        if not categorias:\n",
        "            print(f\"‚ùå No se encontr√≥ la categor√≠a de prueba: {test_category}\")\n",
        "            return\n",
        "        print(f\"üî¨ Modo TEST activado. Procesando solo: {test_category}\")\n",
        "\n",
        "    productos = []\n",
        "    for i, cat in enumerate(categorias, 1):\n",
        "        if test_mode:\n",
        "            if test_category not in cat['url']:\n",
        "                continue\n",
        "            print(f\"\\nüî¨ MODO TEST: Procesando 2 p√°ginas de {cat['categoria_padre']} > {cat['categoria']}\")\n",
        "\n",
        "            todas_paginas = get_all_pages_in_category(cat['url'])\n",
        "            paginas = todas_paginas[:2]\n",
        "            print(f\"  üìë P√°ginas a procesar: {len(paginas)}/{len(todas_paginas)}\")\n",
        "\n",
        "            for j, pagina_url in enumerate(paginas, 1):\n",
        "                try:\n",
        "                    links = get_product_links_from_page(pagina_url)\n",
        "                    print(f\"  üìÑ P√°gina {j}: {len(links)} productos encontrados\")\n",
        "\n",
        "                    for k, link in enumerate(links, 1):\n",
        "                        try:\n",
        "                            print(f\"    üõí ({k}/{len(links)}) Extrayendo: {link.split('/')[-1]}\")\n",
        "                            detalles = extract_product_details(link, cat['categoria_padre'], cat['categoria'])\n",
        "                            productos.append(detalles)\n",
        "                            time.sleep(0.3)\n",
        "                        except Exception as e:\n",
        "                            print(f\"    ‚ùå Error en producto: {str(e)}\")\n",
        "                            continue  # Continuar con el siguiente producto\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  ‚ùå Error en p√°gina {pagina_url}: {str(e)}\")\n",
        "                    continue  # Continuar con la siguiente p√°gina\n",
        "\n",
        "            break  # Salir despu√©s de procesar la categor√≠a de prueba\n",
        "\n",
        "            # Verificar l√≠mite de productos DESPU√âS de procesar cada p√°gina\n",
        "            if test_mode and len(productos) >= 15:\n",
        "                break  # Salir del bucle de p√°ginas si alcanzamos el l√≠mite\n",
        "\n",
        "            # Este break est√° correctamente alineado con el for de p√°ginas\n",
        "            break  # Salir despu√©s de procesar la categor√≠a de prueba\n",
        "\n",
        "\n",
        "\n",
        "    # Guardar resultados\n",
        "    if productos:\n",
        "        filename = \"productos_test.csv\" if test_mode else \"productos_farmaferrer.csv\"\n",
        "        save_to_csv(productos, filename)\n",
        "        print(f\"\\n‚úÖ Proceso completado. Datos guardados en {filename}\")\n",
        "        print(f\"üìä Total de productos extra√≠dos: {len(productos)}\")\n",
        "    else:\n",
        "        print(\"\\n‚ùå No se extrajeron productos\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ejecutar en modo test con la categor√≠a de desodorantes\n",
        "    main(test_mode=True, test_category=\"https://www.farmaferrer.com/higiene/higiene-corporal/desodorantes\")"
      ]
    }
  ]
}